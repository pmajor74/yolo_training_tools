"""Enhanced HTML report generator for comprehensive benchmark results."""

from datetime import datetime
from pathlib import Path
from typing import Dict, Any, List, Optional
import json
import base64
from io import BytesIO
import traceback
import numpy as np

from .confusion_matrix_generator import ConfusionMatrixGenerator
from .benchmark_visualizer import BenchmarkVisualizer


class EnhancedBenchmarkReportGenerator:
    """Generate comprehensive interactive HTML reports for benchmark results."""
    
    def __init__(self):
        """Initialize the enhanced report generator."""
        self.confusion_gen = None
        self.visualizer = None
        
    def generate_report(self, results: Dict[str, Any], 
                       detailed_image_results: Optional[List[Dict]] = None) -> str:
        """Generate a comprehensive HTML report with dual views.
        
        Args:
            results: Complete benchmark results from AdvancedBenchmarkCalculator
            detailed_image_results: Per-image detailed results
            
        Returns:
            HTML string with complete interactive report
        """
        try:
            metadata = results.get('metadata', {})
            timestamp = metadata.get('timestamp', datetime.now().isoformat())
            
            # Initialize generators
            class_names = metadata.get('class_names', {})
            self.confusion_gen = ConfusionMatrixGenerator(class_names)
            self.visualizer = BenchmarkVisualizer(class_names)
            
            # Generate HTML sections
            html = f"""<!DOCTYPE html>
<html lang="en">
<head>
    <title>YOLO Benchmark Report - Enhanced</title>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <script src="https://cdn.plot.ly/plotly-latest.min.js"></script>
    <style>
        {self._get_enhanced_css_styles()}
    </style>
</head>
<body>
    <div class="container">
        <div class="header">
            <h1>üéØ YOLO Model Benchmark Report</h1>
            <div class="header-info">
                <span class="model-name">{Path(metadata.get('model_path', 'Unknown')).name}</span>
                <span class="timestamp">{datetime.fromisoformat(timestamp).strftime('%Y-%m-%d %H:%M:%S')}</span>
            </div>
            <div class="view-toggle">
                <button class="view-btn active" onclick="showView('executive')">Executive Summary</button>
                <button class="view-btn" onclick="showView('technical')">Technical Details</button>
                <button class="view-btn" onclick="showView('files')">File Results</button>
            </div>
        </div>
        
        <div id="executive-view" class="view-content">
            {self._generate_executive_summary(results)}
            {self._generate_key_metrics_cards(results)}
            {self._generate_performance_overview(results)}
            {self._generate_business_recommendations(results)}
        </div>
        
        <div id="technical-view" class="view-content" style="display: none;">
            {self._generate_technical_metrics(results)}
            {self._generate_confusion_matrix_section(results)}
            {self._generate_pr_curves_section(results)}
            {self._generate_detailed_error_analysis(results, detailed_image_results)}
            {self._generate_per_image_details_section(detailed_image_results)}
        </div>
        
        <div id="files-view" class="view-content" style="display: none;">
            {self._generate_detailed_file_list(results, detailed_image_results)}
        </div>
        
        <div class="footer">
            <div class="export-buttons">
                <button onclick="exportToPDF()">üìÑ Export to PDF</button>
                <button onclick="exportToCSV()">üìä Export Data to CSV</button>
                <button onclick="window.print()">üñ®Ô∏è Print Report</button>
            </div>
            <p>Generated by YOLO Training Tools - Advanced Benchmarking System v2.0</p>
        </div>
    </div>
    
    <script>
        {self._get_javascript_functions()}
    </script>
</body>
</html>"""
            
            return html
            
        except Exception as e:
            print(f"[ERROR] EnhancedBenchmarkReportGenerator.generate_report: {str(e)}")
            traceback.print_exc()
            return self._generate_error_report(str(e))
            
    def _get_enhanced_css_styles(self) -> str:
        """Get enhanced CSS styles for the report."""
        return """
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }
        
        :root {
            --primary-color: #667eea;
            --secondary-color: #764ba2;
            --success-color: #4caf50;
            --warning-color: #ff9800;
            --danger-color: #f44336;
            --bg-color: #f5f5f5;
            --card-bg: white;
            --text-primary: #333;
            --text-secondary: #666;
        }
        
        body {
            font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Oxygen, Ubuntu, sans-serif;
            background: linear-gradient(135deg, var(--primary-color) 0%, var(--secondary-color) 100%);
            min-height: 100vh;
            padding: 20px;
            color: var(--text-primary);
        }
        
        .container {
            max-width: 1800px;
            margin: 0 auto;
            background: var(--card-bg);
            border-radius: 20px;
            box-shadow: 0 25px 60px rgba(0,0,0,0.15);
            overflow: hidden;
        }
        
        .header {
            background: linear-gradient(135deg, var(--primary-color) 0%, var(--secondary-color) 100%);
            color: white;
            padding: 40px;
            position: relative;
        }
        
        .header h1 {
            font-size: 2.8em;
            margin-bottom: 15px;
            text-shadow: 2px 2px 6px rgba(0,0,0,0.2);
        }
        
        .header-info {
            display: flex;
            justify-content: space-between;
            align-items: center;
            margin-bottom: 20px;
            opacity: 0.95;
        }
        
        .model-name {
            font-size: 1.2em;
            font-weight: 600;
            padding: 8px 16px;
            background: rgba(255,255,255,0.2);
            border-radius: 20px;
        }
        
        .timestamp {
            font-size: 0.95em;
        }
        
        .view-toggle {
            display: flex;
            gap: 10px;
            margin-top: 20px;
        }
        
        .view-btn {
            padding: 12px 24px;
            background: rgba(255,255,255,0.2);
            color: white;
            border: 2px solid rgba(255,255,255,0.3);
            border-radius: 8px;
            cursor: pointer;
            font-size: 1em;
            font-weight: 600;
            transition: all 0.3s ease;
        }
        
        .view-btn:hover {
            background: rgba(255,255,255,0.3);
            transform: translateY(-2px);
        }
        
        .view-btn.active {
            background: white;
            color: var(--primary-color);
        }
        
        .view-content {
            padding: 40px;
            animation: fadeIn 0.5s ease;
        }
        
        @keyframes fadeIn {
            from { opacity: 0; transform: translateY(20px); }
            to { opacity: 1; transform: translateY(0); }
        }
        
        .metric-cards {
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(250px, 1fr));
            gap: 20px;
            margin: 30px 0;
        }
        
        .metric-card {
            background: var(--card-bg);
            padding: 25px;
            border-radius: 15px;
            box-shadow: 0 5px 15px rgba(0,0,0,0.08);
            border-left: 4px solid var(--primary-color);
            transition: all 0.3s ease;
        }
        
        .metric-card:hover {
            transform: translateY(-5px);
            box-shadow: 0 10px 25px rgba(0,0,0,0.15);
        }
        
        .metric-card h3 {
            color: var(--text-secondary);
            font-size: 0.95em;
            margin-bottom: 10px;
            text-transform: uppercase;
            letter-spacing: 1px;
        }
        
        .metric-value {
            font-size: 2.5em;
            font-weight: bold;
            color: var(--primary-color);
            margin-bottom: 5px;
        }
        
        .metric-subtitle {
            color: var(--text-secondary);
            font-size: 0.9em;
        }
        
        .performance-badge {
            display: inline-block;
            padding: 6px 12px;
            border-radius: 20px;
            font-weight: 600;
            font-size: 0.9em;
            margin-left: 10px;
        }
        
        .badge-excellent { background: var(--success-color); color: white; }
        .badge-good { background: #8bc34a; color: white; }
        .badge-fair { background: var(--warning-color); color: white; }
        .badge-poor { background: var(--danger-color); color: white; }
        
        .section {
            margin: 40px 0;
            padding: 30px;
            background: var(--bg-color);
            border-radius: 12px;
        }
        
        .section-header {
            font-size: 1.8em;
            color: var(--text-primary);
            margin-bottom: 20px;
            padding-bottom: 10px;
            border-bottom: 3px solid var(--primary-color);
        }
        
        .progress-bar {
            width: 100%;
            height: 30px;
            background: #e0e0e0;
            border-radius: 15px;
            overflow: hidden;
            margin: 10px 0;
            position: relative;
        }
        
        .progress-fill {
            height: 100%;
            background: linear-gradient(90deg, var(--primary-color), var(--secondary-color));
            display: flex;
            align-items: center;
            justify-content: center;
            color: white;
            font-weight: bold;
            transition: width 0.5s ease;
        }
        
        .recommendation {
            padding: 20px;
            margin: 15px 0;
            border-radius: 10px;
            border-left: 5px solid;
        }
        
        .recommendation.excellent {
            background: #e8f5e9;
            border-color: var(--success-color);
        }
        
        .recommendation.warning {
            background: #fff3e0;
            border-color: var(--warning-color);
        }
        
        .recommendation.critical {
            background: #ffebee;
            border-color: var(--danger-color);
        }
        
        .error-card {
            background: white;
            border-radius: 10px;
            padding: 20px;
            margin: 15px 0;
            border: 1px solid #e0e0e0;
            cursor: pointer;
            transition: all 0.3s ease;
        }
        
        .error-card:hover {
            box-shadow: 0 5px 15px rgba(0,0,0,0.1);
        }
        
        .error-card-header {
            display: flex;
            justify-content: space-between;
            align-items: center;
            margin-bottom: 15px;
        }
        
        .error-severity {
            padding: 4px 12px;
            border-radius: 12px;
            font-size: 0.85em;
            font-weight: 600;
        }
        
        .severity-critical { background: var(--danger-color); color: white; }
        .severity-high { background: #ff6b6b; color: white; }
        .severity-medium { background: var(--warning-color); color: white; }
        .severity-low { background: #ffd93d; color: #333; }
        
        table {
            width: 100%;
            border-collapse: collapse;
            margin-top: 20px;
        }
        
        th {
            background: var(--primary-color);
            color: white;
            padding: 15px;
            text-align: left;
            font-weight: 600;
        }
        
        td {
            padding: 12px 15px;
            border-bottom: 1px solid #e0e0e0;
        }
        
        tr:nth-child(even) {
            background: #f9f9f9;
        }
        
        tr:hover {
            background: #f0f0f0;
        }
        
        .collapsible-section {
            margin: 20px 0;
        }
        
        .collapsible-header {
            background: var(--primary-color);
            color: white;
            padding: 15px 20px;
            border-radius: 8px;
            cursor: pointer;
            font-size: 1.2em;
            font-weight: 600;
            display: flex;
            justify-content: space-between;
            align-items: center;
            transition: background 0.3s ease;
        }
        
        .collapsible-header:hover {
            background: var(--secondary-color);
        }
        
        .collapsible-content {
            max-height: 0;
            overflow: hidden;
            transition: max-height 0.3s ease;
            background: white;
            border: 1px solid #e0e0e0;
            border-top: none;
            border-radius: 0 0 8px 8px;
        }
        
        .collapsible-content.active {
            max-height: 5000px;
            padding: 20px;
        }
        
        .footer {
            background: var(--bg-color);
            padding: 30px;
            text-align: center;
            border-top: 1px solid #e0e0e0;
        }
        
        .export-buttons {
            display: flex;
            gap: 15px;
            justify-content: center;
            margin-bottom: 20px;
        }
        
        .export-buttons button {
            padding: 12px 24px;
            background: var(--primary-color);
            color: white;
            border: none;
            border-radius: 8px;
            cursor: pointer;
            font-size: 1em;
            font-weight: 600;
            transition: all 0.3s ease;
        }
        
        .export-buttons button:hover {
            background: var(--secondary-color);
            transform: translateY(-2px);
        }
        
        @media print {
            body { padding: 0; background: white; }
            .container { box-shadow: none; }
            .view-toggle, .export-buttons { display: none; }
            .collapsible-content { max-height: none !important; }
        }
        
        @media (max-width: 768px) {
            .metric-cards { grid-template-columns: 1fr; }
            .header h1 { font-size: 2em; }
            .export-buttons { flex-direction: column; }
        }
        """
        
    def _get_javascript_functions(self) -> str:
        """Get JavaScript functions for interactivity."""
        return """
        function showView(view) {
            // Hide all views
            document.querySelectorAll('.view-content').forEach(v => v.style.display = 'none');
            // Show selected view
            document.getElementById(view + '-view').style.display = 'block';
            // Update button states
            document.querySelectorAll('.view-btn').forEach(b => b.classList.remove('active'));
            event.target.classList.add('active');
        }
        
        function toggleCollapsible(element) {
            const content = element.nextElementSibling;
            content.classList.toggle('active');
            const arrow = element.querySelector('.arrow');
            if (arrow) {
                arrow.style.transform = content.classList.contains('active') ? 'rotate(90deg)' : 'rotate(0)';
            }
        }
        
        function exportToPDF() {
            // Show all collapsible content
            document.querySelectorAll('.collapsible-content').forEach(c => c.classList.add('active'));
            window.print();
        }
        
        function exportToCSV() {
            // Collect all table data
            const tables = document.querySelectorAll('table');
            let csv = '';
            
            tables.forEach((table, idx) => {
                if (idx > 0) csv += '\\n\\n';
                const rows = table.querySelectorAll('tr');
                rows.forEach(row => {
                    const cells = row.querySelectorAll('th, td');
                    const rowData = Array.from(cells).map(cell => 
                        '"' + cell.textContent.replace(/"/g, '""') + '"'
                    ).join(',');
                    csv += rowData + '\\n';
                });
            });
            
            // Download CSV
            const blob = new Blob([csv], { type: 'text/csv' });
            const url = window.URL.createObjectURL(blob);
            const a = document.createElement('a');
            a.href = url;
            a.download = 'benchmark_data.csv';
            a.click();
            window.URL.revokeObjectURL(url);
        }
        
        // Initialize collapsibles
        document.addEventListener('DOMContentLoaded', function() {
            document.querySelectorAll('.collapsible-header').forEach(header => {
                header.addEventListener('click', function() {
                    toggleCollapsible(this);
                });
            });
        });
        """
        
    def _generate_executive_summary(self, results: Dict) -> str:
        """Generate executive summary section."""
        f1 = results.get('f1_score', 0)
        map50 = results.get('map_50', 0)
        precision = results.get('precision', 0)
        recall = results.get('recall', 0)
        
        # Determine overall performance level
        if f1 >= 0.85:
            performance = "Excellent"
            badge_class = "badge-excellent"
            emoji = "üèÜ"
        elif f1 >= 0.70:
            performance = "Good"
            badge_class = "badge-good"
            emoji = "‚úÖ"
        elif f1 >= 0.50:
            performance = "Fair"
            badge_class = "badge-fair"
            emoji = "‚ö†Ô∏è"
        else:
            performance = "Needs Improvement"
            badge_class = "badge-poor"
            emoji = "‚ö°"
            
        total_images = results.get('total_images', 0)
        total_gt = results.get('total_ground_truth', 0)
        
        return f"""
        <div class="section">
            <h2 class="section-header">Executive Summary</h2>
            <div style="font-size: 1.2em; line-height: 1.8;">
                <p>
                    <strong>Overall Model Performance:</strong> 
                    {emoji} <span class="performance-badge {badge_class}">{performance}</span>
                </p>
                <p style="margin-top: 20px;">
                    The model was evaluated on <strong>{total_images}</strong> test images containing 
                    <strong>{total_gt}</strong> ground truth objects. 
                    It achieved an F1 score of <strong>{f1:.1%}</strong> with a mean Average Precision (mAP@0.5) 
                    of <strong>{map50:.1%}</strong>.
                </p>
                <p style="margin-top: 15px;">
                    The model correctly identified <strong>{recall:.1%}</strong> of all objects (Recall) 
                    with <strong>{precision:.1%}</strong> of its detections being correct (Precision).
                </p>
            </div>
        </div>
        """
        
    def _generate_key_metrics_cards(self, results: Dict) -> str:
        """Generate key metrics cards."""
        metrics = [
            {
                'title': 'F1 Score',
                'value': f"{results.get('f1_score', 0):.1%}",
                'subtitle': 'Overall accuracy',
                'color': self._get_metric_color(results.get('f1_score', 0))
            },
            {
                'title': 'mAP@0.5',
                'value': f"{results.get('map_50', 0):.1%}",
                'subtitle': 'Detection quality',
                'color': self._get_metric_color(results.get('map_50', 0))
            },
            {
                'title': 'mAP@[0.5:0.95]',
                'value': f"{results.get('map_50_95', 0):.1%}",
                'subtitle': 'COCO standard',
                'color': self._get_metric_color(results.get('map_50_95', 0))
            },
            {
                'title': 'Precision',
                'value': f"{results.get('precision', 0):.1%}",
                'subtitle': 'Detection accuracy',
                'color': self._get_metric_color(results.get('precision', 0))
            },
            {
                'title': 'Recall',
                'value': f"{results.get('recall', 0):.1%}",
                'subtitle': 'Detection coverage',
                'color': self._get_metric_color(results.get('recall', 0))
            },
            {
                'title': 'Avg Speed',
                'value': f"{results.get('avg_inference_time', 0):.3f}s",
                'subtitle': 'Per image',
                'color': self._get_speed_color(results.get('avg_inference_time', 0))
            }
        ]
        
        cards_html = []
        for metric in metrics:
            cards_html.append(f"""
                <div class="metric-card" style="border-left-color: {metric['color']};">
                    <h3>{metric['title']}</h3>
                    <div class="metric-value" style="color: {metric['color']};">
                        {metric['value']}
                    </div>
                    <div class="metric-subtitle">{metric['subtitle']}</div>
                </div>
            """)
            
        return f"""
        <div class="metric-cards">
            {''.join(cards_html)}
        </div>
        """
        
    def _generate_performance_overview(self, results: Dict) -> str:
        """Generate performance overview with progress bars."""
        metrics = [
            ('Precision', results.get('precision', 0)),
            ('Recall', results.get('recall', 0)),
            ('F1 Score', results.get('f1_score', 0)),
            ('mAP@0.5', results.get('map_50', 0)),
            ('mAP@0.75', results.get('map_75', 0)),
            ('mAP@[0.5:0.95]', results.get('map_50_95', 0))
        ]
        
        bars_html = []
        for name, value in metrics:
            percentage = value * 100
            color = self._get_metric_color(value)
            bars_html.append(f"""
                <div style="margin: 20px 0;">
                    <div style="display: flex; justify-content: space-between; margin-bottom: 5px;">
                        <strong>{name}</strong>
                        <span style="color: {color}; font-weight: bold;">{percentage:.1f}%</span>
                    </div>
                    <div class="progress-bar">
                        <div class="progress-fill" style="width: {percentage}%; background: {color};">
                        </div>
                    </div>
                </div>
            """)
            
        return f"""
        <div class="section">
            <h2 class="section-header">Performance Overview</h2>
            {''.join(bars_html)}
        </div>
        """
        
    def _generate_business_recommendations(self, results: Dict) -> str:
        """Generate business-friendly recommendations."""
        recommendations = []
        
        f1 = results.get('f1_score', 0)
        precision = results.get('precision', 0)
        recall = results.get('recall', 0)
        avg_time = results.get('avg_inference_time', 0)
        
        # Performance assessment
        if f1 >= 0.85:
            recommendations.append({
                'type': 'excellent',
                'title': 'üéØ Production Ready',
                'text': 'Model shows excellent performance and is ready for production deployment.'
            })
        elif f1 >= 0.70:
            recommendations.append({
                'type': 'excellent',
                'title': '‚úÖ Good Performance',
                'text': 'Model performs well and is suitable for most applications.'
            })
        elif f1 >= 0.50:
            recommendations.append({
                'type': 'warning',
                'title': '‚ö†Ô∏è Additional Training Recommended',
                'text': 'Model shows fair performance. Consider additional training with more diverse data.'
            })
        else:
            recommendations.append({
                'type': 'critical',
                'title': '‚ö° Significant Improvement Needed',
                'text': 'Model requires substantial improvement before deployment.'
            })
            
        # Precision vs Recall balance
        if abs(precision - recall) > 0.2:
            if precision > recall:
                recommendations.append({
                    'type': 'warning',
                    'title': 'üîç Low Recall Detected',
                    'text': f'Model misses {(1-recall)*100:.0f}% of objects. Consider lowering confidence threshold or adding more training examples.'
                })
            else:
                recommendations.append({
                    'type': 'warning',
                    'title': '‚ö†Ô∏è Low Precision Detected',
                    'text': f'{(1-precision)*100:.0f}% of detections are false positives. Consider raising confidence threshold or improving training data quality.'
                })
                
        # Speed assessment
        if avg_time < 0.05:
            recommendations.append({
                'type': 'excellent',
                'title': 'üöÄ Real-time Capable',
                'text': f'Inference speed of {1/avg_time:.0f} FPS enables real-time applications.'
            })
        elif avg_time < 0.1:
            recommendations.append({
                'type': 'excellent',
                'title': '‚ö° Fast Processing',
                'text': f'Good inference speed of {1/avg_time:.0f} FPS suitable for near real-time use.'
            })
        elif avg_time > 1.0:
            recommendations.append({
                'type': 'warning',
                'title': 'üêå Slow Inference',
                'text': 'Consider model optimization or hardware acceleration for production use.'
            })
            
        rec_html = []
        for rec in recommendations:
            rec_html.append(f"""
                <div class="recommendation {rec['type']}">
                    <h4 style="margin: 0 0 10px 0;">{rec['title']}</h4>
                    <p style="margin: 0;">{rec['text']}</p>
                </div>
            """)
            
        return f"""
        <div class="section">
            <h2 class="section-header">Recommendations</h2>
            {''.join(rec_html)}
        </div>
        """
        
    def _generate_technical_metrics(self, results: Dict) -> str:
        """Generate detailed technical metrics section."""
        overall_metrics = results.get('overall_metrics_by_iou', {})
        
        # Create table for metrics at different IoU thresholds
        rows = []
        for iou_thresh in sorted(overall_metrics.keys()):
            metrics = overall_metrics[iou_thresh]
            rows.append(f"""
                <tr>
                    <td><strong>{iou_thresh:.2f}</strong></td>
                    <td>{metrics.get('precision', 0):.4f}</td>
                    <td>{metrics.get('recall', 0):.4f}</td>
                    <td>{metrics.get('f1_score', 0):.4f}</td>
                    <td>{metrics.get('true_positives', 0)}</td>
                    <td>{metrics.get('false_positives', 0)}</td>
                    <td>{metrics.get('false_negatives', 0)}</td>
                </tr>
            """)
            
        return f"""
        <div class="section">
            <h2 class="section-header">Technical Metrics at Different IoU Thresholds</h2>
            <table>
                <thead>
                    <tr>
                        <th>IoU Threshold</th>
                        <th>Precision</th>
                        <th>Recall</th>
                        <th>F1 Score</th>
                        <th>True Positives</th>
                        <th>False Positives</th>
                        <th>False Negatives</th>
                    </tr>
                </thead>
                <tbody>
                    {''.join(rows)}
                </tbody>
            </table>
        </div>
        """
        
    def _generate_confusion_matrix_section(self, results: Dict) -> str:
        """Generate confusion matrix visualization section."""
        confusion_matrix = np.array(results.get('confusion_matrix', []))
        
        if confusion_matrix.size == 0:
            return ""
            
        matrix_html = self.confusion_gen.generate_html_heatmap(
            confusion_matrix, 
            normalize=True,
            title="Detection Confusion Matrix"
        )
        
        analysis = self.confusion_gen.generate_class_confusion_analysis(confusion_matrix)
        summary = self.confusion_gen.generate_summary_metrics(confusion_matrix)
        
        return f"""
        <div class="section">
            <h2 class="section-header">Confusion Matrix Analysis</h2>
            <div style="margin: 20px 0;">
                <p><strong>Overall Accuracy:</strong> {summary['overall_accuracy']:.1%}</p>
                <p><strong>Mean Class Accuracy:</strong> {summary['mean_class_accuracy']:.1%}</p>
            </div>
            {matrix_html}
        </div>
        """
        
    def _generate_pr_curves_section(self, results: Dict) -> str:
        """Generate precision-recall curves section."""
        # For now, using placeholder data
        # In production, this would use actual PR curve data
        per_class_metrics = results.get('per_class_metrics', {})
        
        # Generate mock PR curve data
        pr_data = {
            'precision_recall_curve': {
                'precision': [1.0, 0.9, 0.85, 0.8, 0.75, 0.7],
                'recall': [0.0, 0.3, 0.5, 0.7, 0.85, 1.0]
            }
        }
        
        # Add to per-class metrics
        enhanced_per_class = {}
        for class_name, metrics in per_class_metrics.items():
            enhanced_per_class[class_name] = metrics
            enhanced_per_class[class_name]['precision_recall_curve'] = pr_data['precision_recall_curve']
            
        pr_html = self.visualizer.generate_pr_curves_html(enhanced_per_class, pr_data)
        
        return f"""
        <div class="section">
            <h2 class="section-header">Precision-Recall Analysis</h2>
            {pr_html}
        </div>
        """
        
    def _generate_detailed_error_analysis(self, results: Dict, 
                                         detailed_image_results: Optional[List[Dict]]) -> str:
        """Generate detailed error analysis section."""
        if not detailed_image_results:
            return ""
            
        # Collect error statistics
        total_errors = 0
        error_types = {
            'localization': 0,
            'classification': 0,
            'background_fp': 0,
            'missed': 0
        }
        
        problem_images = []
        
        for img_result in detailed_image_results:
            if 'error_analysis' in img_result:
                errors = img_result['error_analysis']
                if errors.get('localization_errors'):
                    error_types['localization'] += len(errors['localization_errors'])
                if errors.get('classification_errors'):
                    error_types['classification'] += len(errors['classification_errors'])
                if errors.get('background_fps'):
                    error_types['background_fp'] += len(errors['background_fps'])
                if errors.get('missed_detections'):
                    error_types['missed'] += len(errors['missed_detections'])
                    
                # Check if this is a problem image
                metrics_50 = img_result.get('metrics_by_iou', {}).get(0.5, {})
                if metrics_50.get('false_positives', 0) > 0 or metrics_50.get('false_negatives', 0) > 0:
                    problem_images.append({
                        'path': img_result.get('image_path', 'Unknown'),
                        'fp': metrics_50.get('false_positives', 0),
                        'fn': metrics_50.get('false_negatives', 0),
                        'f1': metrics_50.get('f1_score', 0)
                    })
                    
        # Sort problem images by F1 score (worst first)
        problem_images.sort(key=lambda x: x['f1'])
        
        # Create error type chart
        error_chart = f"""
        <div style="margin: 30px 0;">
            <h3>Error Type Distribution</h3>
            <div id="error-types-chart" style="height: 400px;"></div>
        </div>
        
        <script>
            (function() {{
                const data = [{{
                    values: {list(error_types.values())},
                    labels: ['Localization', 'Classification', 'Background FP', 'Missed'],
                    type: 'pie',
                    marker: {{
                        colors: ['#ff9800', '#f44336', '#e91e63', '#9c27b0']
                    }}
                }}];
                
                const layout = {{
                    title: 'Distribution of Error Types',
                    height: 400
                }};
                
                Plotly.newPlot('error-types-chart', data, layout, {{responsive: true}});
            }})();
        </script>
        """
        
        # Create problem images table
        problem_rows = []
        for i, img in enumerate(problem_images[:20]):  # Show top 20
            severity = self._get_severity(img['f1'])
            problem_rows.append(f"""
                <div class="error-card">
                    <div class="error-card-header">
                        <strong>{Path(img['path']).name}</strong>
                        <span class="error-severity severity-{severity}">{severity.upper()}</span>
                    </div>
                    <div style="display: grid; grid-template-columns: repeat(3, 1fr); gap: 15px;">
                        <div>
                            <strong>False Positives:</strong> {img['fp']}
                        </div>
                        <div>
                            <strong>Missed:</strong> {img['fn']}
                        </div>
                        <div>
                            <strong>F1 Score:</strong> {img['f1']:.1%}
                        </div>
                    </div>
                </div>
            """)
            
        return f"""
        <div class="section">
            <h2 class="section-header">Detailed Error Analysis</h2>
            {error_chart}
            
            <div class="collapsible-section">
                <div class="collapsible-header" onclick="toggleCollapsible(this)">
                    Problem Images (Click to expand)
                    <span class="arrow" style="transition: transform 0.3s;">‚ñ∂</span>
                </div>
                <div class="collapsible-content">
                    <p style="margin-bottom: 20px;">
                        Images with detection issues, sorted by worst performance first.
                    </p>
                    {''.join(problem_rows)}
                </div>
            </div>
        </div>
        """
        
    def _generate_detailed_file_list(self, results: Dict, detailed_image_results: Optional[List[Dict]]) -> str:
        """Generate detailed file list with ground truth vs predictions."""
        if not detailed_image_results:
            return "<div class='section'><p>No detailed image results available.</p></div>"
            
        metadata = results.get('metadata', {})
        class_names = metadata.get('class_names', {})
        
        # Ensure class_names keys are integers
        class_name_map = {}
        for k, v in class_names.items():
            try:
                class_name_map[int(k)] = v
            except (ValueError, TypeError):
                continue
                
        rows = []
        for idx, img_result in enumerate(detailed_image_results):
            image_path = img_result.get('image_path', 'Unknown')
            image_name = Path(image_path).name
            
            # Make the path clickable (file:// protocol for local files)
            if Path(image_path).exists():
                # Convert to absolute path and use proper file URI
                abs_path = Path(image_path).resolve()
                file_uri = abs_path.as_uri()
                image_link = f'<a href="{file_uri}" target="_blank" title="Click to open image">{image_name}</a>'
            else:
                image_link = image_name
                
            # Get ground truth labels
            gt_details = img_result.get('ground_truth_details', [])
            gt_labels = {}
            for gt in gt_details:
                class_id = gt.get('class_id', -1)
                class_name = class_name_map.get(class_id, f'Class_{class_id}')
                gt_labels[class_name] = gt_labels.get(class_name, 0) + 1
                
            # Format ground truth
            if gt_labels:
                gt_text = ', '.join([f'{name}({count})' for name, count in sorted(gt_labels.items())])
            else:
                gt_text = '<span style="color: #999;">None</span>'
                
            # Get prediction labels
            pred_details = img_result.get('prediction_details', [])
            pred_labels = {}
            pred_confidences = {}
            for pred in pred_details:
                class_id = pred.get('class_id', -1)
                class_name = class_name_map.get(class_id, f'Class_{class_id}')
                confidence = pred.get('confidence', 0)
                
                if class_name not in pred_labels:
                    pred_labels[class_name] = 0
                    pred_confidences[class_name] = []
                    
                pred_labels[class_name] += 1
                pred_confidences[class_name].append(confidence)
                
            # Format predictions with average confidence
            if pred_labels:
                pred_parts = []
                for name, count in sorted(pred_labels.items()):
                    avg_conf = sum(pred_confidences[name]) / len(pred_confidences[name])
                    pred_parts.append(f'{name}({count})@{avg_conf:.0%}')
                pred_text = ', '.join(pred_parts)
            else:
                pred_text = '<span style="color: #999;">None</span>'
                
            # Get metrics at IoU 0.5
            metrics_50 = img_result.get('metrics_by_iou', {}).get(0.5, {})
            tp = metrics_50.get('true_positives', 0)
            fp = metrics_50.get('false_positives', 0)
            fn = metrics_50.get('false_negatives', 0)
            precision = metrics_50.get('precision', 0)
            recall = metrics_50.get('recall', 0)
            f1 = metrics_50.get('f1_score', 0)
            
            # Determine row color based on performance
            row_class = ''
            if f1 == 1.0:
                row_class = 'perfect-row'
            elif f1 >= 0.8:
                row_class = 'good-row'
            elif f1 >= 0.5:
                row_class = 'fair-row'
            elif f1 > 0:
                row_class = 'poor-row'
            else:
                row_class = 'failed-row'
                
            rows.append(f'''
                <tr class="{row_class}">
                    <td>{idx + 1}</td>
                    <td class="file-link">{image_link}</td>
                    <td>{gt_text}</td>
                    <td>{pred_text}</td>
                    <td class="metric-cell">{tp}</td>
                    <td class="metric-cell">{fp}</td>
                    <td class="metric-cell">{fn}</td>
                    <td class="metric-cell">{precision:.1%}</td>
                    <td class="metric-cell">{recall:.1%}</td>
                    <td class="metric-cell">{f1:.1%}</td>
                </tr>
            ''')
            
        return f'''
        <div class="section">
            <h2 class="section-header">Detailed File Results</h2>
            <p style="margin-bottom: 20px;">
                Complete list of all test images with their ground truth labels and model predictions.
                Click on any filename to open the image in a new tab.
            </p>
            
            <div class="file-list-controls">
                <input type="text" id="file-search" placeholder="Search files..." onkeyup="filterFileTable()">
                <label>
                    <input type="checkbox" id="show-errors-only" onchange="filterFileTable()">
                    Show only files with errors
                </label>
            </div>
            
            <div style="overflow-x: auto;">
                <table id="file-results-table" class="file-results-table">
                    <thead>
                        <tr>
                            <th>#</th>
                            <th>File Name</th>
                            <th>Ground Truth</th>
                            <th>Predictions</th>
                            <th>TP</th>
                            <th>FP</th>
                            <th>FN</th>
                            <th>Precision</th>
                            <th>Recall</th>
                            <th>F1</th>
                        </tr>
                    </thead>
                    <tbody>
                        {''.join(rows)}
                    </tbody>
                </table>
            </div>
            
            <div class="file-summary" style="margin-top: 20px; padding: 15px; background: #f5f5f5; border-radius: 5px;">
                <strong>Summary:</strong> {len(rows)} files processed
            </div>
        </div>
        
        <style>
            .file-results-table {{
                width: 100%;
                border-collapse: collapse;
                margin-top: 20px;
                font-size: 0.95em;
            }}
            .file-results-table th {{
                background: var(--primary-color);
                color: white;
                padding: 12px;
                text-align: left;
                position: sticky;
                top: 0;
                z-index: 10;
            }}
            .file-results-table td {{
                padding: 10px 12px;
                border-bottom: 1px solid #e0e0e0;
            }}
            .file-results-table tr:hover {{
                background: #f0f0f0;
            }}
            .file-link a {{
                color: var(--primary-color);
                text-decoration: none;
                font-weight: 500;
            }}
            .file-link a:hover {{
                text-decoration: underline;
            }}
            .metric-cell {{
                text-align: center;
                font-family: monospace;
            }}
            .perfect-row {{
                background: rgba(76, 175, 80, 0.1);
            }}
            .good-row {{
                background: rgba(139, 195, 74, 0.1);
            }}
            .fair-row {{
                background: rgba(255, 193, 7, 0.1);
            }}
            .poor-row {{
                background: rgba(255, 152, 0, 0.1);
            }}
            .failed-row {{
                background: rgba(244, 67, 54, 0.1);
            }}
            .file-list-controls {{
                display: flex;
                gap: 20px;
                align-items: center;
                margin-bottom: 15px;
            }}
            #file-search {{
                padding: 8px 12px;
                border: 1px solid #ddd;
                border-radius: 4px;
                font-size: 14px;
                flex: 1;
                max-width: 300px;
            }}
        </style>
        
        <script>
            function filterFileTable() {{
                const searchInput = document.getElementById('file-search');
                const showErrorsOnly = document.getElementById('show-errors-only').checked;
                const filter = searchInput.value.toLowerCase();
                const table = document.getElementById('file-results-table');
                const rows = table.getElementsByTagName('tbody')[0].getElementsByTagName('tr');
                
                for (let i = 0; i < rows.length; i++) {{
                    const cells = rows[i].getElementsByTagName('td');
                    const fileName = cells[1].textContent || cells[1].innerText;
                    const fp = parseInt(cells[4].textContent) || 0;
                    const fn = parseInt(cells[5].textContent) || 0;
                    
                    let showRow = true;
                    
                    // Check search filter
                    if (filter && !fileName.toLowerCase().includes(filter)) {{
                        showRow = false;
                    }}
                    
                    // Check errors filter
                    if (showErrorsOnly && fp === 0 && fn === 0) {{
                        showRow = false;
                    }}
                    
                    rows[i].style.display = showRow ? '' : 'none';
                }}
                
                // Update summary
                const visibleRows = Array.from(rows).filter(r => r.style.display !== 'none').length;
                const summary = document.querySelector('.file-summary');
                if (summary) {{
                    let text = `<strong>Summary:</strong> Showing ${{visibleRows}} of ${{rows.length}} files`;
                    if (showErrorsOnly) {{
                        text += ' (errors only)';
                    }}
                    if (filter) {{
                        text += ` matching "${{filter}}"`;
                    }}
                    summary.innerHTML = text;
                }}
            }}
        </script>
        '''
        
    def _generate_per_image_details_section(self, detailed_image_results: Optional[List[Dict]]) -> str:
        """Generate per-image detailed results section."""
        if not detailed_image_results:
            return ""
            
        rows = []
        for img_result in detailed_image_results:
            metrics_50 = img_result.get('metrics_by_iou', {}).get(0.5, {})
            rows.append(f"""
                <tr>
                    <td>{Path(img_result.get('image_path', 'Unknown')).name}</td>
                    <td>{img_result.get('ground_truth_count', 0)}</td>
                    <td>{img_result.get('prediction_count', 0)}</td>
                    <td>{metrics_50.get('true_positives', 0)}</td>
                    <td>{metrics_50.get('false_positives', 0)}</td>
                    <td>{metrics_50.get('false_negatives', 0)}</td>
                    <td>{metrics_50.get('precision', 0):.1%}</td>
                    <td>{metrics_50.get('recall', 0):.1%}</td>
                    <td>{metrics_50.get('f1_score', 0):.1%}</td>
                </tr>
            """)
            
        return f"""
        <div class="section">
            <div class="collapsible-section">
                <div class="collapsible-header" onclick="toggleCollapsible(this)">
                    Per-Image Results (Click to expand)
                    <span class="arrow" style="transition: transform 0.3s;">‚ñ∂</span>
                </div>
                <div class="collapsible-content">
                    <table>
                        <thead>
                            <tr>
                                <th>Image</th>
                                <th>GT</th>
                                <th>Pred</th>
                                <th>TP</th>
                                <th>FP</th>
                                <th>FN</th>
                                <th>Precision</th>
                                <th>Recall</th>
                                <th>F1</th>
                            </tr>
                        </thead>
                        <tbody>
                            {''.join(rows[:100])}
                        </tbody>
                    </table>
                    {f'<p>Showing first 100 of {len(rows)} images</p>' if len(rows) > 100 else ''}
                </div>
            </div>
        </div>
        """
        
    def _get_metric_color(self, value: float) -> str:
        """Get color based on metric value."""
        if value >= 0.8:
            return 'var(--success-color)'
        elif value >= 0.6:
            return '#8bc34a'
        elif value >= 0.4:
            return 'var(--warning-color)'
        else:
            return 'var(--danger-color)'
            
    def _get_speed_color(self, time: float) -> str:
        """Get color based on inference time."""
        if time < 0.05:
            return 'var(--success-color)'
        elif time < 0.1:
            return '#8bc34a'
        elif time < 0.5:
            return 'var(--warning-color)'
        else:
            return 'var(--danger-color)'
            
    def _get_severity(self, f1_score: float) -> str:
        """Get severity level based on F1 score."""
        if f1_score == 0:
            return 'critical'
        elif f1_score < 0.3:
            return 'high'
        elif f1_score < 0.6:
            return 'medium'
        else:
            return 'low'
            
    def _generate_error_report(self, error_msg: str) -> str:
        """Generate error report when generation fails."""
        return f"""
        <!DOCTYPE html>
        <html>
        <head>
            <title>Report Generation Error</title>
            <style>
                body {{ font-family: sans-serif; padding: 40px; background: #f5f5f5; }}
                .error {{ background: white; padding: 30px; border-radius: 10px; 
                         border-left: 5px solid #f44336; }}
                h1 {{ color: #f44336; }}
                pre {{ background: #f0f0f0; padding: 15px; border-radius: 5px; overflow-x: auto; }}
            </style>
        </head>
        <body>
            <div class="error">
                <h1>Report Generation Failed</h1>
                <p>An error occurred while generating the benchmark report.</p>
                <pre>{error_msg}</pre>
                <p>Please check the benchmark results data and try again.</p>
            </div>
        </body>
        </html>
        """